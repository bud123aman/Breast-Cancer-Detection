{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0707244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T09:29:25.775298Z",
     "iopub.status.busy": "2025-10-12T09:29:25.775068Z",
     "iopub.status.idle": "2025-10-12T09:29:46.977878Z",
     "shell.execute_reply": "2025-10-12T09:29:46.977288Z"
    },
    "papermill": {
     "duration": 21.206936,
     "end_time": "2025-10-12T09:29:46.979303",
     "exception": false,
     "start_time": "2025-10-12T09:29:25.772367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-12 09:29:29.089317: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760261369.316972      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760261369.402213      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests, re, time, datetime\n",
    "from urllib.parse import urlparse\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dabf6dc2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-12T09:29:46.984380Z",
     "iopub.status.busy": "2025-10-12T09:29:46.983780Z",
     "iopub.status.idle": "2025-10-12T09:29:47.008515Z",
     "shell.execute_reply": "2025-10-12T09:29:47.007896Z"
    },
    "papermill": {
     "duration": 0.028119,
     "end_time": "2025-10-12T09:29:47.009532",
     "exception": false,
     "start_time": "2025-10-12T09:29:46.981413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "CONFIG = {\n",
    "    \"data_path\": \"/kaggle/input/dataset\",\n",
    "    \"text_features_dim\": 300,\n",
    "    \"model_save_path\": \"/kaggle/working/ensemble_model.pkl\",\n",
    "    \"text_max_length\": 200,\n",
    "}\n",
    "\n",
    "class EfficientFeatureExtractor:\n",
    "    def __init__(self):\n",
    "        self.text_vectorizer = TfidfVectorizer(\n",
    "            max_features=CONFIG[\"text_features_dim\"],\n",
    "            ngram_range=(1, 2),\n",
    "            stop_words='english'\n",
    "        )\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def extract_text_features(self, texts):\n",
    "        if not hasattr(self, 'text_vectorizer_fitted'):\n",
    "            self.text_vectorizer.fit(texts)\n",
    "            self.text_vectorizer_fitted = True\n",
    "        return self.text_vectorizer.transform(texts).toarray()\n",
    "    \n",
    "    def extract_simple_image_features(self, image_urls):\n",
    "        \"\"\"Extract simple image features without deep learning\"\"\"\n",
    "        features = []\n",
    "        for url in image_urls:\n",
    "            try:\n",
    "                if isinstance(url, str) and url.startswith('http'):\n",
    "                    has_image = 1\n",
    "                    \n",
    "                    parsed_url = urlparse(url)\n",
    "                    domain = parsed_url.netloc\n",
    "                    \n",
    "                    is_cdn = 1 if any(cdn in domain for cdn in ['cdn', 'cloudfront', 'amazonaws', 'googleapis']) else 0\n",
    "                    is_secure = 1 if url.startswith('https') else 0\n",
    "                    \n",
    "                    file_ext = os.path.splitext(parsed_url.path)[1].lower()\n",
    "                    is_jpg = 1 if file_ext in ['.jpg', '.jpeg'] else 0\n",
    "                    is_png = 1 if file_ext == '.png' else 0\n",
    "                    is_webp = 1 if file_ext == '.webp' else 0\n",
    "                    \n",
    "                    feature_vector = [has_image, is_cdn, is_secure, is_jpg, is_png, is_webp]\n",
    "                    \n",
    "                else:\n",
    "                    feature_vector = [0, 0, 0, 0, 0, 0]\n",
    "            except:\n",
    "                feature_vector = [0, 0, 0, 0, 0, 0]\n",
    "            \n",
    "            features.append(feature_vector)\n",
    "        return np.array(features)\n",
    "    \n",
    "    def extract_advanced_features(self, df):\n",
    "        text_features = self.extract_text_features(df['cleaned_content'].fillna(''))\n",
    "        image_features = self.extract_simple_image_features(df['image_link'].fillna(''))\n",
    "        numerical_features = self._extract_numerical_features(df)\n",
    "        \n",
    "        all_features = np.hstack([text_features, image_features, numerical_features])\n",
    "        \n",
    "        return all_features\n",
    "    \n",
    "    def _extract_numerical_features(self, df):\n",
    "        features = []\n",
    "        \n",
    "        features.append(df['cleaned_content'].str.len().fillna(0).values.reshape(-1, 1))\n",
    "        features.append(df['cleaned_content'].str.split().str.len().fillna(0).values.reshape(-1, 1))\n",
    "        \n",
    "        features.append(df['ipq'].values.reshape(-1, 1))\n",
    "        features.append((df['ipq'] > 1).astype(int).values.reshape(-1, 1))\n",
    "        features.append((df['ipq'] > 10).astype(int).values.reshape(-1, 1))\n",
    "        \n",
    "        price_keywords = ['premium', 'luxury', 'designer', 'professional', 'quality', 'deluxe']\n",
    "        for keyword in price_keywords:\n",
    "            features.append(df['cleaned_content'].str.contains(keyword).astype(int).values.reshape(-1, 1))\n",
    "        \n",
    "        product_types = ['shirt', 'shoe', 'electronic', 'book', 'tool', 'toy', 'watch', 'phone', 'computer']\n",
    "        for ptype in product_types:\n",
    "            features.append(df['cleaned_content'].str.contains(ptype).astype(int).values.reshape(-1, 1))\n",
    "        \n",
    "        features.append(df['catalog_content'].str.contains(r'\\$|\\€|\\£').astype(int).values.reshape(-1, 1))\n",
    "        features.append(df['catalog_content'].str.contains(r'\\d+\\.\\d{2}').astype(int).values.reshape(-1, 1))\n",
    "        \n",
    "        return np.hstack(features)\n",
    "\n",
    "def extract_ipq(text):\n",
    "    if not isinstance(text, str): \n",
    "        return 1\n",
    "    \n",
    "    text = text.lower()\n",
    "    patterns = [\n",
    "        r'pack\\s+of\\s+(\\d+)', r'(\\d+)\\s*pack', r'(\\d+)\\s*count', \n",
    "        r'set\\s+of\\s+(\\d+)', r'(\\d+)\\s*pcs', r'(\\d+)\\s*pieces', \n",
    "        r'(\\d+)\\s*ct', r'case\\s+of\\s+(\\d+)', r'(\\d+)\\s*unit',\n",
    "        r'(\\d+)\\s*-?piece', r'(\\d+)\\s*-?pack'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            try:\n",
    "                value = int(match.group(1))\n",
    "                return min(max(value, 1), 100)\n",
    "            except ValueError: \n",
    "                continue\n",
    "    return 1\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str): \n",
    "        return \"\"\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s$€£¥%+]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def preprocess_data(df, is_train=True):\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    df_processed['catalog_content'] = df_processed['catalog_content'].fillna('')\n",
    "    \n",
    "    df_processed['ipq'] = df_processed['catalog_content'].apply(extract_ipq)\n",
    "    df_processed['cleaned_content'] = df_processed['catalog_content'].apply(clean_text)\n",
    "    \n",
    "    df_processed['text_length'] = df_processed['cleaned_content'].str.len()\n",
    "    df_processed['word_count'] = df_processed['cleaned_content'].str.split().str.len()\n",
    "    \n",
    "    if is_train and 'price' in df_processed.columns:\n",
    "        df_processed['price'] = df_processed['price'].fillna(df_processed['price'].median())\n",
    "        df_processed['log_price'] = np.log1p(df_processed['price'])\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "class EnsemblePricePredictor:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.feature_extractor = EfficientFeatureExtractor()\n",
    "        self.is_trained = False\n",
    "        \n",
    "    def create_models(self):\n",
    "        self.models = {\n",
    "            'xgb': xgb.XGBRegressor(\n",
    "                n_estimators=500,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=8,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            ),\n",
    "            'lgb': lgb.LGBMRegressor(\n",
    "                n_estimators=500,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=8,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        self.ensemble = VotingRegressor([\n",
    "            ('xgb', self.models['xgb']),\n",
    "            ('lgb', self.models['lgb'])\n",
    "        ])\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        self.create_models()\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            model.fit(X, y)\n",
    "        \n",
    "        self.ensemble.fit(X, y)\n",
    "        self.is_trained = True\n",
    "        \n",
    "    def predict(self, X):\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model not trained yet\")\n",
    "        return self.ensemble.predict(X)\n",
    "    \n",
    "    def save(self, path):\n",
    "        joblib.dump({\n",
    "            'ensemble': self.ensemble,\n",
    "            'feature_extractor': self.feature_extractor\n",
    "        }, path)\n",
    "    \n",
    "    def load(self, path):\n",
    "        saved_data = joblib.load(path)\n",
    "        self.ensemble = saved_data['ensemble']\n",
    "        self.feature_extractor = saved_data['feature_extractor']\n",
    "        self.is_trained = True\n",
    "\n",
    "def calculate_smape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred))\n",
    "    smape_values = np.where(denominator == 0, 0, 2 * np.abs(y_pred - y_true) / denominator)\n",
    "    return 100 * np.mean(smape_values)\n",
    "\n",
    "def prepare_data():\n",
    "    train_path = os.path.join(CONFIG[\"data_path\"], \"train.csv\")\n",
    "    test_path = os.path.join(CONFIG[\"data_path\"], \"test.csv\")\n",
    "    \n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    \n",
    "    train_df = preprocess_data(train_df, is_train=True)\n",
    "    test_df = preprocess_data(test_df, is_train=False)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "def predictor(sample_id, catalog_content, image_link):\n",
    "    sample_df = pd.DataFrame([{\n",
    "        'sample_id': sample_id,\n",
    "        'catalog_content': catalog_content,\n",
    "        'image_link': image_link\n",
    "    }])\n",
    "    \n",
    "    sample_df = preprocess_data(sample_df, is_train=False)\n",
    "    \n",
    "    predictor = EnsemblePricePredictor()\n",
    "    predictor.load(CONFIG[\"model_save_path\"])\n",
    "    \n",
    "    features = predictor.feature_extractor.extract_advanced_features(sample_df)\n",
    "    \n",
    "    log_prediction = predictor.predict(features)[0]\n",
    "    predicted_price = np.expm1(log_prediction)\n",
    "    \n",
    "    predicted_price = max(0.1, min(predicted_price, 1000.0))\n",
    "    \n",
    "    return predicted_price\n",
    "\n",
    "def train_and_predict():\n",
    "    try:\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        train_df, test_df = prepare_data()\n",
    "        \n",
    "        feature_extractor = EfficientFeatureExtractor()\n",
    "        predictor = EnsemblePricePredictor()\n",
    "        predictor.feature_extractor = feature_extractor\n",
    "        \n",
    "        X_train = feature_extractor.extract_advanced_features(train_df)\n",
    "        y_train = train_df['log_price'].values\n",
    "        \n",
    "        predictor.train(X_train, y_train)\n",
    "        \n",
    "        predictor.save(CONFIG[\"model_save_path\"])\n",
    "        \n",
    "        X_test = feature_extractor.extract_advanced_features(test_df)\n",
    "        log_predictions = predictor.predict(X_test)\n",
    "        predictions = np.expm1(log_predictions)\n",
    "        \n",
    "        submission_df = pd.DataFrame({\n",
    "            'sample_id': test_df['sample_id'],\n",
    "            'price': predictions\n",
    "        })\n",
    "        \n",
    "        train_prices = pd.read_csv(os.path.join(CONFIG[\"data_path\"], \"train.csv\"))['price']\n",
    "        median_price = train_prices.median()\n",
    "        submission_df['price'] = submission_df['price'].fillna(median_price).clip(0.1, 1000.0)\n",
    "        \n",
    "        submission_df.to_csv(\"/kaggle/working/output.csv\", index=False)\n",
    "        \n",
    "        val_predictions = predictor.predict(X_train[:100])\n",
    "        val_true = y_train[:100]\n",
    "        smape_score = calculate_smape(np.expm1(val_true), np.expm1(val_predictions))\n",
    "        print(f\"{smape_score:.2f}\")\n",
    "        \n",
    "        return predictor, submission_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0183a52b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T09:29:47.013068Z",
     "iopub.status.busy": "2025-10-12T09:29:47.012888Z",
     "iopub.status.idle": "2025-10-12T09:33:09.657469Z",
     "shell.execute_reply": "2025-10-12T09:33:09.656806Z"
    },
    "papermill": {
     "duration": 202.64768,
     "end_time": "2025-10-12T09:33:09.658687",
     "exception": false,
     "start_time": "2025-10-12T09:29:47.011007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 77044\n",
      "[LightGBM] [Info] Number of data points in the train set: 75000, number of used features: 319\n",
      "[LightGBM] [Info] Start training from score 2.739217\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.101011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 77044\n",
      "[LightGBM] [Info] Number of data points in the train set: 75000, number of used features: 319\n",
      "[LightGBM] [Info] Start training from score 2.739217\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "57.18\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model, predictions = train_and_predict()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8464150,
     "sourceId": 13346865,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 231.117777,
   "end_time": "2025-10-12T09:33:13.149500",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-12T09:29:22.031723",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
